{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceed1594-841c-44cc-85dd-2c7cba444a66",
   "metadata": {},
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64fc7199-530f-4aca-bdab-eaa973e755af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/conda/lib/python3.11/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/conda/lib/python3.11/site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/conda/lib/python3.11/site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b932962-c6b4-4455-9d49-bcafcb7a8c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: modin[ray] in /opt/conda/lib/python3.11/site-packages (0.32.0)\n",
      "Requirement already satisfied: pandas<2.3,>=2.2 in /opt/conda/lib/python3.11/site-packages (from modin[ray]) (2.2.2)\n",
      "Requirement already satisfied: packaging>=21.0 in /opt/conda/lib/python3.11/site-packages (from modin[ray]) (24.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.11/site-packages (from modin[ray]) (1.26.4)\n",
      "Requirement already satisfied: fsspec>=2022.11.0 in /opt/conda/lib/python3.11/site-packages (from modin[ray]) (2023.6.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.11/site-packages (from modin[ray]) (5.9.8)\n",
      "Requirement already satisfied: ray!=2.5.0,>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from modin[ray]) (2.31.0)\n",
      "Requirement already satisfied: pyarrow>=10.0.1 in /opt/conda/lib/python3.11/site-packages (from modin[ray]) (15.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas<2.3,>=2.2->modin[ray]) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas<2.3,>=2.2->modin[ray]) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas<2.3,>=2.2->modin[ray]) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas<2.3,>=2.2->modin[ray]) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install modin[ray]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85d13bed-7926-4a2d-8f6a-cec156491adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d340fcac-041d-46b5-a89d-f415574cc192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-01 06:17:08.371419: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-01 06:17:08.388072: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-01 06:17:08.393214: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-01 06:17:08.406233: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17ace5f5-feac-4dce-a633-5855a2aba8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727763439.739788   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727763439.741552   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727763439.743290   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727763439.744923   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727763439.812253   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727763439.814098   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727763439.816015   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727763439.817586   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727763439.819246   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727763439.820814   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727763439.822496   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727763439.824104   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94289d38-5675-4176-a542-d37eb03abd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21a8f51a-4ffa-41ac-a57b-eaa57d34f8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, roc_auc_score\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Adagrad\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.losses import BinaryFocalCrossentropy\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import os\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8791b5ec-8909-4ba7-b172-30f1d0c9085a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/mnt/sagemaker-nvme/ray_temp’: File exists\n",
      "mkdir: cannot create directory ‘/mnt/sagemaker-nvme/ray_temp_plasma’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir /mnt/sagemaker-nvme/ray_temp\n",
    "!mkdir /mnt/sagemaker-nvme/ray_temp_plasma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96a8eab1-641b-4c38-b986-e6bf8139bdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import modin.pandas as pd\n",
    "# import ray\n",
    "\n",
    "# ray_info = ray.init(\n",
    "#     _system_config={\n",
    "#     \"object_spilling_config\": json.dumps(\n",
    "#         {\"type\": \"filesystem\", \"params\": {\"directory_path\": \"/mnt/sagemaker-nvme/ray_lstm_spelling\"}},\n",
    "#     )\n",
    "#     },\n",
    "#     object_store_memory=(107374182400), # Allocates 100 GB to Ray Plasma memory, which stores object on available memory space.\n",
    "#     _temp_dir=\"/mnt/sagemaker-nvme/ray_temp\",\n",
    "#     _plasma_directory=\"/mnt/sagemaker-nvme/ray_temp_plasma\",\n",
    "#     ignore_reinit_error=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de37c3bc-6933-46f7-9a71-afbc9e443a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ray_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7cad4d5-9dea-4d95-9799-7a17a55e7f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Get information about Ray nodes\n",
    "# ray_info.address_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecc7a8e0-1cf6-40fa-b386-af6be138ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "NVMe_PATH = '/mnt/sagemaker-nvme/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f5c87a-f340-4918-9a2f-da07ee24f6b0",
   "metadata": {},
   "source": [
    "# 2. Download dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4def5972-7333-496d-8ba8-f27080a23e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/sagemaker-nvme/training_after_preproc.csv\n",
      "/mnt/sagemaker-nvme/testing_after_preproc.csv\n"
     ]
    }
   ],
   "source": [
    "training_file_name = \"training_after_preproc.csv\"\n",
    "testing_file_name = \"testing_after_preproc.csv\"\n",
    "NVMe_Training_file_Path = NVMe_PATH+training_file_name\n",
    "NVMe_Testing_file_Path = NVMe_PATH+testing_file_name\n",
    "\n",
    "print(NVMe_Training_file_Path)\n",
    "print(NVMe_Testing_file_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87d9344a-b919-47ba-98ed-da131f8f23e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49 μs, sys: 36 μs, total: 85 μs\n",
      "Wall time: 59.1 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if os.path.exists(NVMe_Training_file_Path):\n",
    "    pass\n",
    "else:\n",
    "    !aws s3 cp s3://melbahae-capstone/Datasets/training_after_preproc.csv /mnt/sagemaker-nvme/\n",
    "\n",
    "if os.path.exists(NVMe_Testing_file_Path):\n",
    "    pass\n",
    "else:\n",
    "    !aws s3 cp s3://melbahae-capstone/Datasets/testing_after_preproc.csv /mnt/sagemaker-nvme/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa759000-f4c4-452d-9537-60e4f907621a",
   "metadata": {},
   "source": [
    "# 3. Load and Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a95c1a2-9a75-4713-9efc-e4adf29743cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 25s, sys: 34.9 s, total: 8min 59s\n",
      "Wall time: 9min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "training_df = pd.read_csv(NVMe_Training_file_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bb7a346-c7fe-4c9b-9cc2-e77abdee71b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 19s, sys: 7.64 s, total: 3min 26s\n",
      "Wall time: 3min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "testing_df = pd.read_csv(NVMe_Testing_file_Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836e51b1-fe18-41f1-9d2b-eee1d06db663",
   "metadata": {},
   "source": [
    "# Reducing dataset memory footprint:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c9731f-4549-4e7b-bac6-41565b743c4f",
   "metadata": {},
   "source": [
    "## Downscaling numerical features:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70dcc47-e817-4231-a081-12d4019f5e87",
   "metadata": {},
   "source": [
    "By downscaling the datatype for numerical features, e.g: changing dtype of a column from int64 instead of int16, it saves memory space an ensure efficient allocation of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "837de851-22c7-4073-b33c-9a42f0d9d4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df):\n",
    "    # Iterate over all columns\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        \n",
    "        # Only process numerical columns\n",
    "        if np.issubdtype(col_type, np.number):\n",
    "            if np.issubdtype(col_type, np.integer):\n",
    "                # Downcast integers\n",
    "                df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "            elif np.issubdtype(col_type, np.floating):\n",
    "                # Downcast floats\n",
    "                df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48ee50a5-45fd-4b37-bcab-ca067ec74ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.2 s, sys: 39.1 ms, total: 16.2 s\n",
      "Wall time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "training_df = reduce_memory_usage(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "529e1f8c-7c01-4b08-9526-99ff5f03d679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.46 s, sys: 15.8 ms, total: 6.48 s\n",
      "Wall time: 6.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "testing_df = reduce_memory_usage(testing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb89fc73-251e-4293-a566-e274cc82ac25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50052497 entries, 0 to 50052496\n",
      "Columns: 160 entries, Total Fwd Packets to Protocol_UDP\n",
      "dtypes: bool(105), float32(20), float64(27), int16(2), int32(1), int8(5)\n",
      "memory usage: 19.3 GB\n"
     ]
    }
   ],
   "source": [
    "training_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "601a993f-33de-4e8a-b680-7cb1e399c5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19963266 entries, 0 to 19963265\n",
      "Columns: 160 entries, Total Fwd Packets to Protocol_UDP\n",
      "dtypes: bool(105), float32(18), float64(29), int16(2), int32(1), int8(5)\n",
      "memory usage: 7.8 GB\n"
     ]
    }
   ],
   "source": [
    "testing_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35686033-18d8-468f-8fdc-3913c6899fd1",
   "metadata": {},
   "source": [
    "## Removing columns with single value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7045da4-ff10-47d0-be03-96b624a21ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.6 s, sys: 0 ns, total: 36.6 s\n",
      "Wall time: 36.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Source IP Class_D',\n",
       " 'Source IP Class_E',\n",
       " 'Destination IP Class_Unknown',\n",
       " 'Source IP Reserved_Multicast',\n",
       " 'Source IP Reserved_Loopback',\n",
       " 'Source IP Reserved_Link-local',\n",
       " 'Source IP Reserved_Reserved',\n",
       " 'Source IP Reserved_Broadcast',\n",
       " 'Source IP Reserved_DHCP/Zeros',\n",
       " 'Destination IP Reserved_Loopback',\n",
       " 'Destination IP Reserved_Link-local',\n",
       " 'Destination IP Reserved_Reserved',\n",
       " 'Destination IP Reserved_Broadcast',\n",
       " 'Destination IP Reserved_DHCP/Zeros',\n",
       " 'Source Port Category_FTP',\n",
       " 'Source Port Category_MS SQL',\n",
       " 'Source Port Category_MySQL',\n",
       " 'Source Port IANA Range_Unknown',\n",
       " 'Destination Port IANA Range_Unknown']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Checking for columns with single value in training_df:\n",
    "\n",
    "single_value_cols = [col for col in training_df.columns if training_df[col].nunique() <= 1]\n",
    "single_value_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf4e700f-e705-4e94-ac95-3447528e6ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50052497, 141), (19963266, 141))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping common_cols from training and testing datasets:\n",
    "\n",
    "training_df = training_df.drop(columns=single_value_cols)\n",
    "testing_df = testing_df.drop(columns=single_value_cols)\n",
    "(training_df.shape, testing_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09322080-d4dd-478f-87d8-380e5a472f39",
   "metadata": {},
   "source": [
    "# Scaling numerical features in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83c55861-3cf5-4411-8724-bffe5a022283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical and boolean columns\n",
    "numerical_cols = training_df.select_dtypes(include=['number']).columns.tolist()\n",
    "boolean_cols = training_df.select_dtypes(include=['bool']).columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8572255-bee2-43d8-ae8b-4a0d6e09666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the MinMaxScaler for numerical columns\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d838197-8953-4a45-a288-2a3d1e3fc13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.4 s, sys: 5.53 s, total: 24 s\n",
      "Wall time: 24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "training_df[numerical_cols] =  scaler.fit_transform(training_df[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fce98b4d-d3ab-407d-adaa-3ec1bf2b63d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.4 s, sys: 2.66 s, total: 10.1 s\n",
      "Wall time: 10.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "testing_df[numerical_cols] =  scaler.fit_transform(testing_df[numerical_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57042680-04b0-4360-87d1-1c21a8d5a970",
   "metadata": {},
   "source": [
    "# Functions to build LSTM Model, and custom evaluation metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9cae72d-aa9c-4c97-9f10-c89e3c0ca4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return F1 scorer:\n",
    "\n",
    "def f1_score_m(y_true, y_pred):\n",
    "    # Cast both y_true and y_pred to float32 for consistency\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.round(y_pred)  # Round the predictions to 0 or 1\n",
    "    \n",
    "    # True Positives (TP)\n",
    "    tp = tf.reduce_sum(tf.cast(y_true * y_pred, 'float32'), axis=0)\n",
    "    \n",
    "    # False Positives (FP)\n",
    "    fp = tf.reduce_sum(tf.cast((1 - y_true) * y_pred, 'float32'), axis=0)\n",
    "    \n",
    "    # False Negatives (FN)\n",
    "    fn = tf.reduce_sum(tf.cast(y_true * (1 - y_pred), 'float32'), axis=0)\n",
    "\n",
    "    # Precision\n",
    "    precision = tp / (tp + fp + tf.keras.backend.epsilon())\n",
    "    \n",
    "    # Recall\n",
    "    recall = tp / (tp + fn + tf.keras.backend.epsilon())\n",
    "    \n",
    "    # F1 Score\n",
    "    f1 = (2 * precision * recall) / (precision + recall +  K.epsilon())\n",
    "    \n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e78f899-0d84-4c36-8015-e606970891e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return FPR\n",
    "\n",
    "def false_positive_rate_m(y_true, y_pred):\n",
    "    \"\"\"False Positive Rate (FPR) metric.\"\"\"\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred > 0.5, 'float32')\n",
    "    fp = K.sum((1 - y_true) * y_pred)\n",
    "    tn = K.sum((1 - y_true) * (1 - y_pred))\n",
    "    fpr = fp / (fp + tn + K.epsilon())\n",
    "    return fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6670f3ec-28a8-4b79-a228-315dd395d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return TPR\n",
    "def true_positive_rate_m(y_true, y_pred):\n",
    "    \"\"\"True Positive Rate (TPR) metric.\"\"\"\n",
    "    # TPR is the same as recall\n",
    "    return recall_m(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa858603-e4c3-4bdd-9e96-f6fe63f666f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return Prceision\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\"\"\"\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred > 0.5, 'float32')\n",
    "    true_positives = K.sum(y_true * y_pred)\n",
    "    predicted_positives = K.sum(y_pred)\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "337cceac-68fd-42cb-94f8-9a9d3a67db9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return Recall\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\"\"\"\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred > 0.5, 'float32')\n",
    "    true_positives = K.sum(y_true * y_pred)\n",
    "    possible_positives = K.sum(y_true)\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4febbc4-48d6-4cf5-b1ab-84c2fd863747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(num_hidden_layers=0, learning_rate=0.001, optimizer_type='adam'):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Defining LSTM layers:\n",
    "    # Input layer\n",
    "    inputs = Input(shape=(1, X_train_reshaped.shape[2]))\n",
    "    x = LSTM(32, return_sequences=(num_hidden_layers > 0))(inputs)\n",
    "    \n",
    "\n",
    "    # Hidden layers\n",
    "    for i in range(num_hidden_layers):\n",
    "        # For all but the last hidden layer, return_sequences=True\n",
    "        return_seq = True if i < num_hidden_layers - 1 else False\n",
    "        x = LSTM(16, return_sequences=return_seq)(x)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    # Creating the model:\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Select optimizer\n",
    "    if optimizer_type == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_type == 'sgd':\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "    elif optimizer_type == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer_type == 'adagrad':\n",
    "        optimizer = Adagrad(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer type: {optimizer_type}\")\n",
    "    \n",
    "    # Compile the model\n",
    "    loss = BinaryFocalCrossentropy(gamma=2.0) # Focal Loss\n",
    "    model.compile(loss=loss, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=[\n",
    "                      'accuracy',\n",
    "                      precision_m,\n",
    "                      recall_m,\n",
    "                      f1_score_m,\n",
    "                      false_positive_rate_m,\n",
    "                      true_positive_rate_m\n",
    "                  ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174ac519-0925-4f7c-aa6f-0b47c1c028b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Evaluating Hyperparameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c81a74-b572-4aab-b7d8-4d6e1d133e35",
   "metadata": {},
   "source": [
    "## Creating small dataset for testing hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "327c4dd7-4353-4f66-b58f-ae4ec4fa0afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_training_df = training_df.sample(frac=0.1, random_state=42)\n",
    "s_testing_df = testing_df.sample(frac=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701b716a-e8e7-4cbf-94e4-997692c89148",
   "metadata": {},
   "source": [
    "### Splitting features and target columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac986672-9a1b-4792-bcbd-614f4cebe433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X_train = s_training_df.drop('is_attack', axis=1)\n",
    "y_train = s_training_df['is_attack']\n",
    "\n",
    "X_test = s_testing_df.drop('is_attack', axis=1)\n",
    "y_test = s_testing_df['is_attack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e9f98c4-c82a-49f9-8eec-6c6f803edaa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((5005250, 140), (5005250,)), ((1996327, 140), (1996327,)))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape, y_train.shape),  (X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8fca40-508f-426d-9ade-ae70521bf1d7",
   "metadata": {},
   "source": [
    "### Converting to Pandas dataframe from training job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563ae411-f317-4c90-a37d-f9bb4479e140",
   "metadata": {},
   "source": [
    "Pandas is more memory efficient than Modin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b71b964f-b728-45c6-a834-685543edce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert to Pandas\n",
    "# X_train = X_train._to_pandas()\n",
    "# X_test = X_test._to_pandas()\n",
    "# y_train = y_train._to_pandas()\n",
    "# y_test = y_test._to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "372041ab-f129-40bf-9fdc-d6292a2a8081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train, X_test, y_train, y_test are all pandas DataFrames/Series.\n"
     ]
    }
   ],
   "source": [
    "# # Confirm that X_train, X_test, y_train, y_test are pandas df, and if they are, shutdown ray:\n",
    "\n",
    "# if isinstance(X_train, mpd.DataFrame) and isinstance(X_test, mpd.DataFrame) and isinstance(y_train, mpd.Series) and isinstance(y_test, mpd.Series):\n",
    "#     print(\"X_train, X_test, y_train, y_test are all pandas DataFrames/Series.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86f6cf8-22a8-4015-8f5d-87af34b92e12",
   "metadata": {},
   "source": [
    "### Converting Boolean features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b7953df-fbb4-4819-92a4-538a23841361",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "# Converting bool columns to integer\n",
    "train_bool_cols = X_train.select_dtypes(include=['bool']).columns\n",
    "X_train[train_bool_cols] = X_train[train_bool_cols].astype(int)\n",
    "X_test[train_bool_cols] = X_test[train_bool_cols].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71c3457-4174-4756-a10d-7da3c4f686f2",
   "metadata": {},
   "source": [
    "## Define the LSTM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc02be0e-fa30-469b-a806-f84a6714ff10",
   "metadata": {},
   "source": [
    "## Createing a function to score LSTM models with F1_measure:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9ac511-9940-4b6f-9dec-da9ef2208210",
   "metadata": {},
   "source": [
    "## Compute Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a173b200-9b98-4ce3-ae10-97dfd4354140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: 446.5783369022127, 1: 0.5005604396791293}\n"
     ]
    }
   ],
   "source": [
    "# Compute class weights\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(\"Class Weights:\", class_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00377bf2-35c8-42fd-9e37-c0b878e35779",
   "metadata": {},
   "source": [
    "## Evaluate LSTM models with differnet Hyper parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777b6913-df77-49cb-ac37-44f8333626cc",
   "metadata": {},
   "source": [
    "### Reshaping X_train and X_test for LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1248bd-ed80-4604-9b93-b8c8940d8a0d",
   "metadata": {},
   "source": [
    "The input for LSTM is formatted as:\n",
    "\n",
    "( number of rows, timestep, Width/No. of features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7661643d-d293-4b3f-b547-d3260dc8ebf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping for LSTM input (samples, timesteps, features)\n",
    "# LSTM expects input in the shape (samples, timesteps, features)\n",
    "X_train_reshaped = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_reshaped = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "y_train = y_train.values \n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e059363-42cc-4694-858c-bcde87021c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5005250, 1, 140), (1996327, 1, 140))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reshaped.shape, X_test_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd938bf-7019-4d90-8028-af28543d35c7",
   "metadata": {},
   "source": [
    "### Testing LSTM to find the best hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75b494ce-5e1d-4c05-98e3-87693516f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save models\n",
    "save_dir = \"/tmp/sagemaker-nvme/model\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e414236-7007-4d9b-ae75-1df307fbf9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 0 hidden layers, learning rate 0.01, optimizer adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 16:44:22.177820: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2242352000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\n",
      "Epoch 1: val_f1_score_m improved from -inf to 0.99830, saving model to /tmp/sagemaker-nvme/model/checkpoint_hidden_0_lr_0.01_opt_adam.keras\n",
      "31283/31283 - 124s - 4ms/step - accuracy: 0.9997 - f1_score_m: 0.9982 - false_positive_rate_m: 0.1314 - loss: 0.0017 - precision_m: 127.8563 - recall_m: 127.8147 - true_positive_rate_m: 127.8147 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 2.4137e-07 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 2: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 121s - 4ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1328 - loss: 2.2813e-08 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 5.3926e-11 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 3: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 121s - 4ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1323 - loss: 9.5352e-12 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 4.9753e-11 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 4: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 121s - 4ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1321 - loss: 5.9426e-12 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 4.3788e-11 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 5: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 121s - 4ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1329 - loss: 4.4003e-12 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 3.9670e-11 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 6: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 121s - 4ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1323 - loss: 3.5143e-12 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 3.6012e-11 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 7: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 121s - 4ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1315 - loss: 2.9322e-12 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 3.3375e-11 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "\u001b[1m62386/62386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 876us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 0 hidden layers, learning rate 0.001, optimizer adam\n",
      "Epoch 1/10\n",
      "\n",
      "Epoch 1: val_f1_score_m improved from -inf to 0.99830, saving model to /tmp/sagemaker-nvme/model/checkpoint_hidden_0_lr_0.001_opt_adam.keras\n",
      "31283/31283 - 124s - 4ms/step - accuracy: 0.9997 - f1_score_m: 0.9982 - false_positive_rate_m: 0.1322 - loss: 0.0019 - precision_m: 127.8563 - recall_m: 127.8175 - true_positive_rate_m: 127.8175 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 1.0309e-05 - val_precision_m: 127.8504 - val_recall_m: 127.8500 - val_true_positive_rate_m: 127.8500\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 2: val_f1_score_m improved from 0.99830 to 0.99830, saving model to /tmp/sagemaker-nvme/model/checkpoint_hidden_0_lr_0.001_opt_adam.keras\n",
      "31283/31283 - 121s - 4ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1319 - loss: 4.9861e-06 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 2.5104e-08 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 3: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 121s - 4ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1316 - loss: 4.6745e-09 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 1.0997e-10 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 4: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 121s - 4ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1318 - loss: 6.7184e-11 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 6.2004e-11 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 5: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 121s - 4ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1318 - loss: 3.4921e-11 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 4.0189e-11 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 6: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 122s - 4ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1329 - loss: 2.4378e-11 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 3.0996e-11 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 7: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 121s - 4ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1323 - loss: 1.8889e-11 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 2.5496e-11 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 8: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 122s - 4ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1326 - loss: 1.5484e-11 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 2.1579e-11 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "\u001b[1m62386/62386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 877us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 0 hidden layers, learning rate 0.0001, optimizer adam\n",
      "Epoch 1/10\n",
      "\n",
      "Epoch 1: val_f1_score_m improved from -inf to 0.99824, saving model to /tmp/sagemaker-nvme/model/checkpoint_hidden_0_lr_0.0001_opt_adam.keras\n",
      "31283/31283 - 124s - 4ms/step - accuracy: 0.9996 - f1_score_m: 0.9981 - false_positive_rate_m: 0.1326 - loss: 0.0062 - precision_m: 127.8563 - recall_m: 127.8036 - true_positive_rate_m: 127.8036 - val_accuracy: 0.9999 - val_f1_score_m: 0.9982 - val_false_positive_rate_m: 0.1341 - val_loss: 1.3889e-04 - val_precision_m: 127.8504 - val_recall_m: 127.8328 - val_true_positive_rate_m: 127.8328\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 2: val_f1_score_m improved from 0.99824 to 0.99830, saving model to /tmp/sagemaker-nvme/model/checkpoint_hidden_0_lr_0.0001_opt_adam.keras\n",
      "31283/31283 - 121s - 4ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1329 - loss: 1.2359e-04 - precision_m: 127.8563 - recall_m: 127.8513 - true_positive_rate_m: 127.8513 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 5.7264e-06 - val_precision_m: 127.8504 - val_recall_m: 127.8500 - val_true_positive_rate_m: 127.8500\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 3: val_f1_score_m improved from 0.99830 to 0.99830, saving model to /tmp/sagemaker-nvme/model/checkpoint_hidden_0_lr_0.0001_opt_adam.keras\n",
      "31283/31283 - 121s - 4ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1324 - loss: 1.5399e-05 - precision_m: 127.8563 - recall_m: 127.8562 - true_positive_rate_m: 127.8562 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 4.4931e-07 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 4: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 121s - 4ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1331 - loss: 1.5978e-06 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 1.3494e-07 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 5: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 121s - 4ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1330 - loss: 1.0164e-07 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 1.2253e-08 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 6: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 121s - 4ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1318 - loss: 6.8692e-09 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 3.7903e-09 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "\u001b[1m62386/62386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 891us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 1 hidden layers, learning rate 0.01, optimizer adam\n",
      "Epoch 1/10\n",
      "\n",
      "Epoch 1: val_f1_score_m improved from -inf to 0.99830, saving model to /tmp/sagemaker-nvme/model/checkpoint_hidden_1_lr_0.01_opt_adam.keras\n",
      "31283/31283 - 156s - 5ms/step - accuracy: 0.9997 - f1_score_m: 0.9982 - false_positive_rate_m: 0.1321 - loss: 0.0013 - precision_m: 127.8563 - recall_m: 127.8239 - true_positive_rate_m: 127.8239 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 1.2086e-08 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 2: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 153s - 5ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1332 - loss: 2.3221e-10 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 1.6215e-11 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 3: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 153s - 5ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1320 - loss: 3.4198e-12 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 8.2380e-12 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 4: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 152s - 5ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1322 - loss: 2.1775e-12 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 5.5858e-12 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 5: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 153s - 5ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1324 - loss: 1.6206e-12 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 4.2221e-12 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 6: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 152s - 5ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1326 - loss: 1.2957e-12 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 3.4028e-12 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 7: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 153s - 5ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1313 - loss: 1.0816e-12 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 2.8439e-12 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 8: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 154s - 5ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1327 - loss: 9.3075e-13 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 2.4489e-12 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 9: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 154s - 5ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1313 - loss: 8.2070e-13 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 2.1580e-12 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 10: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 153s - 5ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1324 - loss: 7.3658e-13 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 1.9296e-12 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "\u001b[1m62386/62386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 1 hidden layers, learning rate 0.001, optimizer adam\n",
      "Epoch 1/10\n",
      "\n",
      "Epoch 1: val_f1_score_m improved from -inf to 0.99830, saving model to /tmp/sagemaker-nvme/model/checkpoint_hidden_1_lr_0.001_opt_adam.keras\n",
      "31283/31283 - 156s - 5ms/step - accuracy: 0.9998 - f1_score_m: 0.9982 - false_positive_rate_m: 0.1331 - loss: 0.0016 - precision_m: 127.8563 - recall_m: 127.8327 - true_positive_rate_m: 127.8327 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 8.3395e-06 - val_precision_m: 127.8504 - val_recall_m: 127.8496 - val_true_positive_rate_m: 127.8496\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 2: val_f1_score_m improved from 0.99830 to 0.99830, saving model to /tmp/sagemaker-nvme/model/checkpoint_hidden_1_lr_0.001_opt_adam.keras\n",
      "31283/31283 - 152s - 5ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1325 - loss: 8.4698e-07 - precision_m: 127.8563 - recall_m: 127.8561 - true_positive_rate_m: 127.8561 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 1.6755e-07 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 3: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 152s - 5ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1325 - loss: 2.8623e-10 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 8.8015e-11 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 4: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 151s - 5ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1324 - loss: 3.2919e-11 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 4.8142e-11 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 5: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 152s - 5ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1333 - loss: 1.9288e-11 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 3.3481e-11 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 6: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 152s - 5ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1328 - loss: 1.3756e-11 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 2.5632e-11 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 7: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 152s - 5ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1320 - loss: 1.0722e-11 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 2.0855e-11 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "\u001b[1m62386/62386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 1 hidden layers, learning rate 0.0001, optimizer adam\n",
      "Epoch 1/10\n",
      "\n",
      "Epoch 1: val_f1_score_m improved from -inf to 0.99829, saving model to /tmp/sagemaker-nvme/model/checkpoint_hidden_1_lr_0.0001_opt_adam.keras\n",
      "31283/31283 - 156s - 5ms/step - accuracy: 0.9984 - f1_score_m: 0.9972 - false_positive_rate_m: 0.1323 - loss: 0.0063 - precision_m: 127.8563 - recall_m: 127.6572 - true_positive_rate_m: 127.6572 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 2.8797e-05 - val_precision_m: 127.8504 - val_recall_m: 127.8455 - val_true_positive_rate_m: 127.8455\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 2: val_f1_score_m improved from 0.99829 to 0.99830, saving model to /tmp/sagemaker-nvme/model/checkpoint_hidden_1_lr_0.0001_opt_adam.keras\n",
      "31283/31283 - 152s - 5ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1324 - loss: 1.6628e-04 - precision_m: 127.8563 - recall_m: 127.8546 - true_positive_rate_m: 127.8546 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 1.3986e-06 - val_precision_m: 127.8504 - val_recall_m: 127.8503 - val_true_positive_rate_m: 127.8503\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 3: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 152s - 5ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1321 - loss: 1.4855e-05 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 4.5816e-07 - val_precision_m: 127.8504 - val_recall_m: 127.8503 - val_true_positive_rate_m: 127.8503\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 4: val_f1_score_m improved from 0.99830 to 0.99830, saving model to /tmp/sagemaker-nvme/model/checkpoint_hidden_1_lr_0.0001_opt_adam.keras\n",
      "31283/31283 - 152s - 5ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1329 - loss: 4.4845e-08 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 3.4281e-09 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 5: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 153s - 5ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1319 - loss: 1.6818e-09 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 3.1031e-09 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 6: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 152s - 5ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1320 - loss: 4.4863e-10 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 9.0321e-10 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "\u001b[1m62386/62386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 2 hidden layers, learning rate 0.01, optimizer adam\n",
      "Epoch 1/10\n",
      "\n",
      "Epoch 1: val_f1_score_m improved from -inf to 0.99830, saving model to /tmp/sagemaker-nvme/model/checkpoint_hidden_2_lr_0.01_opt_adam.keras\n",
      "31283/31283 - 184s - 6ms/step - accuracy: 0.9996 - f1_score_m: 0.9980 - false_positive_rate_m: 0.1319 - loss: 0.0032 - precision_m: 127.8440 - recall_m: 127.8031 - true_positive_rate_m: 127.8031 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 2.1268e-06 - val_precision_m: 127.8504 - val_recall_m: 127.8500 - val_true_positive_rate_m: 127.8500\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 2: val_f1_score_m improved from 0.99830 to 0.99830, saving model to /tmp/sagemaker-nvme/model/checkpoint_hidden_2_lr_0.01_opt_adam.keras\n",
      "31283/31283 - 180s - 6ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1323 - loss: 6.6053e-04 - precision_m: 127.8563 - recall_m: 127.8555 - true_positive_rate_m: 127.8555 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 3.3068e-07 - val_precision_m: 127.8504 - val_recall_m: 127.8503 - val_true_positive_rate_m: 127.8503\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 3: val_f1_score_m improved from 0.99830 to 0.99830, saving model to /tmp/sagemaker-nvme/model/checkpoint_hidden_2_lr_0.01_opt_adam.keras\n",
      "31283/31283 - 181s - 6ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1325 - loss: 4.5583e-07 - precision_m: 127.8563 - recall_m: 127.8562 - true_positive_rate_m: 127.8562 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 7.5486e-06 - val_precision_m: 127.8504 - val_recall_m: 127.8505 - val_true_positive_rate_m: 127.8505\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 4: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 181s - 6ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1317 - loss: 1.5598e-11 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 8.0695e-06 - val_precision_m: 127.8504 - val_recall_m: 127.8505 - val_true_positive_rate_m: 127.8505\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 5: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 181s - 6ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1320 - loss: 5.8890e-12 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 8.2653e-06 - val_precision_m: 127.8504 - val_recall_m: 127.8505 - val_true_positive_rate_m: 127.8505\n",
      "\u001b[1m62386/62386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 2 hidden layers, learning rate 0.001, optimizer adam\n",
      "Epoch 1/10\n",
      "\n",
      "Epoch 1: val_f1_score_m improved from -inf to 0.99830, saving model to /tmp/sagemaker-nvme/model/checkpoint_hidden_2_lr_0.001_opt_adam.keras\n",
      "31283/31283 - 183s - 6ms/step - accuracy: 0.9998 - f1_score_m: 0.9982 - false_positive_rate_m: 0.1327 - loss: 0.0027 - precision_m: 127.8563 - recall_m: 127.8379 - true_positive_rate_m: 127.8379 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 1.7746e-05 - val_precision_m: 127.8504 - val_recall_m: 127.8489 - val_true_positive_rate_m: 127.8489\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 2: val_f1_score_m improved from 0.99830 to 0.99830, saving model to /tmp/sagemaker-nvme/model/checkpoint_hidden_2_lr_0.001_opt_adam.keras\n",
      "31283/31283 - 179s - 6ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1321 - loss: 7.6641e-05 - precision_m: 127.8563 - recall_m: 127.8559 - true_positive_rate_m: 127.8559 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 2.3911e-07 - val_precision_m: 127.8504 - val_recall_m: 127.8503 - val_true_positive_rate_m: 127.8503\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 3: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 180s - 6ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1323 - loss: 3.5730e-04 - precision_m: 127.8563 - recall_m: 127.8562 - true_positive_rate_m: 127.8562 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 2.2938e-07 - val_precision_m: 127.8504 - val_recall_m: 127.8503 - val_true_positive_rate_m: 127.8503\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 4: val_f1_score_m improved from 0.99830 to 0.99830, saving model to /tmp/sagemaker-nvme/model/checkpoint_hidden_2_lr_0.001_opt_adam.keras\n",
      "31283/31283 - 180s - 6ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1325 - loss: 2.0306e-09 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 2.1727e-10 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 5: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 179s - 6ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1317 - loss: 5.0033e-11 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 7.8229e-11 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 6: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 180s - 6ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1321 - loss: 2.7040e-11 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 5.8084e-11 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "\u001b[1m62386/62386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 2 hidden layers, learning rate 0.0001, optimizer adam\n",
      "Epoch 1/10\n",
      "\n",
      "Epoch 1: val_f1_score_m improved from -inf to 0.99828, saving model to /tmp/sagemaker-nvme/model/checkpoint_hidden_2_lr_0.0001_opt_adam.keras\n",
      "31283/31283 - 185s - 6ms/step - accuracy: 0.9996 - f1_score_m: 0.9981 - false_positive_rate_m: 0.1314 - loss: 0.0068 - precision_m: 127.8563 - recall_m: 127.8053 - true_positive_rate_m: 127.8053 - val_accuracy: 0.9999 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 6.1418e-05 - val_precision_m: 127.8504 - val_recall_m: 127.8439 - val_true_positive_rate_m: 127.8439\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 2: val_f1_score_m improved from 0.99828 to 0.99830, saving model to /tmp/sagemaker-nvme/model/checkpoint_hidden_2_lr_0.0001_opt_adam.keras\n",
      "31283/31283 - 182s - 6ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1326 - loss: 6.7698e-05 - precision_m: 127.8563 - recall_m: 127.8546 - true_positive_rate_m: 127.8546 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 2.6381e-07 - val_precision_m: 127.8504 - val_recall_m: 127.8503 - val_true_positive_rate_m: 127.8503\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 3: val_f1_score_m improved from 0.99830 to 0.99830, saving model to /tmp/sagemaker-nvme/model/checkpoint_hidden_2_lr_0.0001_opt_adam.keras\n",
      "31283/31283 - 182s - 6ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1313 - loss: 9.4163e-08 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 2.7219e-08 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 4: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 182s - 6ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1320 - loss: 9.0035e-10 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 7.4994e-09 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 5: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 181s - 6ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1320 - loss: 3.6624e-10 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 6.6638e-09 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 6: val_f1_score_m did not improve from 0.99830\n",
      "31283/31283 - 182s - 6ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1319 - loss: 2.3282e-10 - precision_m: 127.8563 - recall_m: 127.8563 - true_positive_rate_m: 127.8563 - val_accuracy: 1.0000 - val_f1_score_m: 0.9983 - val_false_positive_rate_m: 0.1341 - val_loss: 5.8401e-09 - val_precision_m: 127.8504 - val_recall_m: 127.8504 - val_true_positive_rate_m: 127.8504\n",
      "\u001b[1m62386/62386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "hidden_layers_options = [0, 1, 2]\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "optimizers = ['adam']\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "for optimizer_type in optimizers:\n",
    "    for num_hidden_layers in hidden_layers_options:\n",
    "        for lr in learning_rates:\n",
    "            print(f\"\\nTraining model with {num_hidden_layers} hidden layers, learning rate {lr}, optimizer {optimizer_type}\")\n",
    "            model = create_lstm_model(num_hidden_layers=num_hidden_layers, learning_rate=lr, optimizer_type=optimizer_type)\n",
    "            \n",
    "            # Define model checkpoint to save the best model based on validation F1 score\n",
    "            checkpoint_filepath = f\"{save_dir}/checkpoint_hidden_{num_hidden_layers}_lr_{lr}_opt_{optimizer_type}.keras\"\n",
    "            model_checkpoint = ModelCheckpoint(\n",
    "                checkpoint_filepath,\n",
    "                monitor='false_positive_rate_m',\n",
    "                mode='min',\n",
    "                verbose=2\n",
    "            )\n",
    "            \n",
    "            # Early stopping to prevent overfitting\n",
    "            early_stopping = EarlyStopping(monitor='false_positive_rate_m', mode='min', patience=2,  restore_best_weights=True, start_from_epoch=2 )\n",
    "            \n",
    "            # Train the model\n",
    "            history = model.fit(\n",
    "                X_train_reshaped, y_train,\n",
    "                epochs=10,\n",
    "                batch_size=32,\n",
    "                validation_split=0.2,\n",
    "                class_weight=class_weights,\n",
    "                callbacks=[early_stopping, model_checkpoint],\n",
    "                verbose=2  # Suppress training output for clarity\n",
    "            )\n",
    "            \n",
    "            # Evaluate the model\n",
    "            y_pred_prob = model.predict(X_test_reshaped)\n",
    "            y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "            \n",
    "            # Compute evaluation metrics\n",
    "            report = classification_report(y_test, y_pred, output_dict=True)\n",
    "            roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "            # Save the trained model after each iteration\n",
    "            model_filename = f\"{save_dir}/model_hidden_{num_hidden_layers}_lr_{lr}_opt_{optimizer_type}.keras\"\n",
    "            model.save(model_filename)\n",
    "\n",
    "            # Compute confusion matrix for FPR and TPR\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            tn, fp, fn, tp = cm.ravel()\n",
    "            fpr_value = fp / (fp + tn + 1e-7)\n",
    "            tpr_value = tp / (tp + fn + 1e-7)\n",
    "\n",
    "\n",
    "            \n",
    "            # Store the results\n",
    "            results.append({\n",
    "                'optimizer': optimizer_type,\n",
    "                'hidden_layers': num_hidden_layers,\n",
    "                'learning_rate': lr,\n",
    "                'accuracy': report['accuracy'],\n",
    "                'precision': report['1']['precision'],\n",
    "                'recall': report['1']['recall'],\n",
    "                'f1_score': report['1']['f1-score'],\n",
    "                'roc_auc': roc_auc,\n",
    "                'fpr': fpr_value,\n",
    "                'tpr': tpr_value,\n",
    "                'history': history.history\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "756bd3a3-3377-4745-8b33-bbe1b568ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = mpd.DataFrame(results)\n",
    "\n",
    "# Sort the DataFrame by 'f1_score' in descending order\n",
    "report_df_sorted = results_df.sort_values(by='fpr', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a3cf8c4-00be-4b73-a822-106d7c709afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>optimizer</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>fpr</th>\n",
       "      <th>tpr</th>\n",
       "      <th>history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adam</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'accuracy': [0.9996895790100098, 1.0, 1.0, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adam</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'accuracy': [0.9995542168617249, 0.9999600648...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adam</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'accuracy': [0.9998059272766113, 0.9999987483...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adam</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'accuracy': [0.9996700882911682, 1.0, 1.0, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adam</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'accuracy': [0.9984208941459656, 0.9999859929...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>adam</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'accuracy': [0.9995737075805664, 0.9999930262...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adam</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'accuracy': [0.999843180179596, 0.99999678134...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adam</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'accuracy': [0.9997427463531494, 1.0, 1.0, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>adam</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'accuracy': [0.9995821714401245, 0.9999862909...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  optimizer  hidden_layers  learning_rate  accuracy  precision  recall  \\\n",
       "1      adam              0         0.0010  0.999999   0.999999     1.0   \n",
       "2      adam              0         0.0001  0.999999   0.999999     1.0   \n",
       "4      adam              1         0.0010  0.999998   0.999998     1.0   \n",
       "0      adam              0         0.0100  0.999997   0.999997     1.0   \n",
       "5      adam              1         0.0001  0.999996   0.999996     1.0   \n",
       "6      adam              2         0.0100  0.999995   0.999995     1.0   \n",
       "7      adam              2         0.0010  0.999995   0.999995     1.0   \n",
       "3      adam              1         0.0100  0.999994   0.999994     1.0   \n",
       "8      adam              2         0.0001  0.999993   0.999993     1.0   \n",
       "\n",
       "   f1_score  roc_auc       fpr  tpr  \\\n",
       "1  1.000000      1.0  0.000189  1.0   \n",
       "2  1.000000      1.0  0.000189  1.0   \n",
       "4  0.999999      1.0  0.000756  1.0   \n",
       "0  0.999999      1.0  0.000946  1.0   \n",
       "5  0.999998      1.0  0.001513  1.0   \n",
       "6  0.999997      1.0  0.001891  1.0   \n",
       "7  0.999997      1.0  0.001891  1.0   \n",
       "3  0.999997      1.0  0.002269  1.0   \n",
       "8  0.999996      1.0  0.002648  1.0   \n",
       "\n",
       "                                             history  \n",
       "1  {'accuracy': [0.9996895790100098, 1.0, 1.0, 1....  \n",
       "2  {'accuracy': [0.9995542168617249, 0.9999600648...  \n",
       "4  {'accuracy': [0.9998059272766113, 0.9999987483...  \n",
       "0  {'accuracy': [0.9996700882911682, 1.0, 1.0, 1....  \n",
       "5  {'accuracy': [0.9984208941459656, 0.9999859929...  \n",
       "6  {'accuracy': [0.9995737075805664, 0.9999930262...  \n",
       "7  {'accuracy': [0.999843180179596, 0.99999678134...  \n",
       "3  {'accuracy': [0.9997427463531494, 1.0, 1.0, 1....  \n",
       "8  {'accuracy': [0.9995821714401245, 0.9999862909...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4a5ad6-06b7-4290-a33c-5a4d64657fcb",
   "metadata": {},
   "source": [
    "Best model with the lowest fpr, used Adam for optomizatin, with no hidden layers, and 0.001 learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9f2bc0-b242-4fb2-8e12-817bb41a6006",
   "metadata": {},
   "source": [
    "# Training Model with Large dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de09dac6-e8cd-4ea7-8d5c-20407f9259d6",
   "metadata": {},
   "source": [
    "## Creating training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "533cd7e3-5a52-4a5f-8420-93248a017927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50052497 entries, 0 to 50052496\n",
      "Columns: 141 entries, Total Fwd Packets to Protocol_UDP\n",
      "dtypes: bool(86), float64(55)\n",
      "memory usage: 24.5 GB\n"
     ]
    }
   ],
   "source": [
    "training_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35f46d75-5f6c-445e-9f4b-93336d9940fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19963266 entries, 0 to 19963265\n",
      "Columns: 141 entries, Total Fwd Packets to Protocol_UDP\n",
      "dtypes: bool(86), float64(55)\n",
      "memory usage: 9.8 GB\n"
     ]
    }
   ],
   "source": [
    "testing_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "653e9b64-109e-4ee3-807e-91e7198262cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_training_df = training_df.sample(frac=0.5, random_state=42)\n",
    "s_testing_df = testing_df.sample(frac=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe9e52ee-8450-474a-8b72-da6082139f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.5 s, sys: 11.3 s, total: 32.9 s\n",
      "Wall time: 32.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Separate features and target\n",
    "X_train = training_df.drop('is_attack', axis=1)\n",
    "y_train = training_df['is_attack']\n",
    "\n",
    "X_test = testing_df.drop('is_attack', axis=1)\n",
    "y_test = testing_df['is_attack']\n",
    "\n",
    "(X_train.shape, y_train.shape),  (X_test.shape,  y_test.shape)\n",
    "\n",
    "# Converting to Boolean\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "# Converting bool columns to integer\n",
    "train_bool_cols = X_train.select_dtypes(include=['bool']).columns\n",
    "X_train[train_bool_cols] = X_train[train_bool_cols].astype(int)\n",
    "X_test[train_bool_cols] = X_test[train_bool_cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd59ab8f-83bc-4ee2-a5f3-7a892e905d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: 440.9678519197223, 1: 0.500567578312266}\n",
      "CPU times: user 5.47 s, sys: 229 ms, total: 5.7 s\n",
      "Wall time: 5.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Compute Class Weights:\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(\"Class Weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bdaa5b41-0f1f-42cd-a8a9-6af17d0cf7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 35 μs, total: 35 μs\n",
      "Wall time: 44.3 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(((50052497, 140), (50052497,)), ((19963266, 140), (19963266,)))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "(X_train.shape, y_train.shape),  (X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c3dfe93-9bd9-4f2b-86ac-6e13bfc1a166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.52 s, sys: 56.4 s, total: 1min 1s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Reshaping for LSTM input (samples, timesteps, features)\n",
    "X_train_reshaped = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_reshaped = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "y_train = y_train.values \n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "893c8c91-649a-447e-ac25-c072aa99e24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1db1f8e5-0169-4ef0-a414-9e2915c622eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), dtype('int64'))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reshaped.dtype, y_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526b641b-9ef6-4280-8fec-184083b2cb65",
   "metadata": {},
   "source": [
    "## Training the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3491f7ca-5946-452e-8125-6db74d9fd6f6",
   "metadata": {},
   "source": [
    "Best model with the lowest fpr, used Adam for optomizatin, with no hidden layers, and 0.001 learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5aea718d-1cbc-495e-9fdb-3ebfa945e22b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1727775261.803318   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727775261.805435   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727775261.807132   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727775261.809351   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727775261.811095   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727775261.813011   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727775261.814754   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727775261.816338   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727775261.817989   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727775261.819664   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727775261.821257   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727775261.823150   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727775261.852714   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727775261.854724   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727775261.856491   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727775261.858190   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727775261.859893   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727775261.861472   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727775261.863295   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727775261.864860   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727775261.866741   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-01 09:34:21.868583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20723 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1b.0, compute capability: 8.6\n",
      "I0000 00:00:1727775261.869069   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-01 09:34:21.870499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 20723 MB memory:  -> device: 1, name: NVIDIA A10G, pci bus id: 0000:00:1c.0, compute capability: 8.6\n",
      "I0000 00:00:1727775261.870839   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-01 09:34:21.872497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 20723 MB memory:  -> device: 2, name: NVIDIA A10G, pci bus id: 0000:00:1d.0, compute capability: 8.6\n",
      "I0000 00:00:1727775261.872912   48017 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-01 09:34:21.874545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 20723 MB memory:  -> device: 3, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n",
      "2024-10-01 09:34:21.879937: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 28029397760 exceeds 10% of free system memory.\n",
      "2024-10-01 09:34:44.633015: W external/local_tsl/tsl/framework/bfc_allocator.cc:482] Allocator (GPU_0_bfc) ran out of memory trying to allocate 26.10GiB (rounded to 28029397760)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-10-01 09:34:44.633049: I external/local_tsl/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2024-10-01 09:34:44.633060: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-10-01 09:34:44.633069: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-10-01 09:34:44.633078: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-10-01 09:34:44.633086: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-10-01 09:34:44.633095: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-10-01 09:34:44.633103: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-10-01 09:34:44.633112: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-10-01 09:34:44.633120: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-10-01 09:34:44.633129: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-10-01 09:34:44.633137: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-10-01 09:34:44.633146: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-10-01 09:34:44.633154: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-10-01 09:34:44.633163: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-10-01 09:34:44.633172: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-10-01 09:34:44.633180: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-10-01 09:34:44.633189: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-10-01 09:34:44.633197: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-10-01 09:34:44.633209: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-10-01 09:34:44.633217: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-10-01 09:34:44.633226: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-10-01 09:34:44.633234: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-10-01 09:34:44.633244: I external/local_tsl/tsl/framework/bfc_allocator.cc:1062] Bin for 26.10GiB was 256.00MiB, Chunk State: \n",
      "2024-10-01 09:34:44.633252: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2024-10-01 09:34:44.633260: I external/local_tsl/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 0B\n",
      "2024-10-01 09:34:44.633269: I external/local_tsl/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 0 memory_limit_: 21730033664 available bytes: 21730033664 curr_region_allocation_bytes_: 21730033664\n",
      "2024-10-01 09:34:44.633280: I external/local_tsl/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                     21730033664\n",
      "InUse:                               0\n",
      "MaxInUse:                            0\n",
      "NumAllocs:                           0\n",
      "MaxAllocSize:                        0\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-10-01 09:34:44.633288: W external/local_tsl/tsl/framework/bfc_allocator.cc:494] <allocator contains no memory>\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create TensorFlow Dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mshuffle(buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)  \u001b[38;5;66;03m# Adjust buffer_size as needed\u001b[39;00m\n\u001b[1;32m      4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m16\u001b[39m)  \u001b[38;5;66;03m# Use your batch size\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py:826\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# from_tensor_slices_op -> dataset_ops).\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_tensor_slices_op\n\u001b[0;32m--> 826\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_tensor_slices_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:25\u001b[0m, in \u001b[0;36m_from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_tensor_slices\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 25\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_TensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:33\u001b[0m, in \u001b[0;36m_TensorSliceDataset.__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, is_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     32\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"See `Dataset.from_tensor_slices` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m   element \u001b[38;5;241m=\u001b[39m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m   batched_spec \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mtype_spec_from_value(element)\n\u001b[1;32m     35\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/data/util/structure.py:134\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    131\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(spec, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    133\u001b[0m         normalized_components\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 134\u001b[0m             \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomponent_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mpack_sequence_as(pack_as, normalized_components)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:713\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[1;32m    712\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[0;32m--> 713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/framework/constant_tensor_conversion.py:29\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constant_op  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     28\u001b[0m _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:276\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(\n\u001b[1;32m    179\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    180\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ops\u001b[38;5;241m.\u001b[39mOperation, ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase]:\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:289\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    288\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 289\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39m_create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    292\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    293\u001b[0m )\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:301\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(\n\u001b[1;32m    298\u001b[0m     ctx, value, dtype, shape, verify_shape\n\u001b[1;32m    299\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase:\n\u001b[1;32m    300\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "# Create TensorFlow Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train_reshaped, y_train))\n",
    "dataset = dataset.shuffle(buffer_size=100)  # Adjust buffer_size as needed\n",
    "dataset = dataset.batch(16)  # Use your batch size\n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2fe4d1a0-cb7f-4238-8062-2703627ca31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 0 hidden layers, learning rate 0.001, optimizer adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-01 10:08:29.164183: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 22423518320 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\n",
      "Epoch 1: saving model to /home/sagemaker-user/model/checkpoint_hidden_0_lr_0.001_opt_adam.keras\n",
      "312829/312829 - 753s - 2ms/step - accuracy: 1.0000 - f1_score_m: 0.9982 - false_positive_rate_m: 0.1491 - loss: 1.9448e-04 - precision_m: 127.9123 - recall_m: 127.9084 - true_positive_rate_m: 127.9084 - val_accuracy: 1.0000 - val_f1_score_m: 0.9992 - val_false_positive_rate_m: 0.0243 - val_loss: 3.8112e-13 - val_precision_m: 127.9232 - val_recall_m: 127.9232 - val_true_positive_rate_m: 127.9232\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 2: saving model to /home/sagemaker-user/model/checkpoint_hidden_0_lr_0.001_opt_adam.keras\n",
      "312829/312829 - 749s - 2ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1486 - loss: 4.7817e-12 - precision_m: 127.9119 - recall_m: 127.9119 - true_positive_rate_m: 127.9119 - val_accuracy: 1.0000 - val_f1_score_m: 0.9992 - val_false_positive_rate_m: 0.0243 - val_loss: 2.1451e-13 - val_precision_m: 127.9232 - val_recall_m: 127.9232 - val_true_positive_rate_m: 127.9232\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 3: saving model to /home/sagemaker-user/model/checkpoint_hidden_0_lr_0.001_opt_adam.keras\n",
      "312829/312829 - 748s - 2ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1489 - loss: 2.2274e-12 - precision_m: 127.9116 - recall_m: 127.9116 - true_positive_rate_m: 127.9116 - val_accuracy: 1.0000 - val_f1_score_m: 0.9992 - val_false_positive_rate_m: 0.0243 - val_loss: 1.7161e-13 - val_precision_m: 127.9232 - val_recall_m: 127.9232 - val_true_positive_rate_m: 127.9232\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 4: saving model to /home/sagemaker-user/model/checkpoint_hidden_0_lr_0.001_opt_adam.keras\n",
      "312829/312829 - 748s - 2ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1490 - loss: 1.5719e-12 - precision_m: 127.9120 - recall_m: 127.9120 - true_positive_rate_m: 127.9120 - val_accuracy: 1.0000 - val_f1_score_m: 0.9992 - val_false_positive_rate_m: 0.0243 - val_loss: 1.5611e-13 - val_precision_m: 127.9232 - val_recall_m: 127.9232 - val_true_positive_rate_m: 127.9232\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 5: saving model to /home/sagemaker-user/model/checkpoint_hidden_0_lr_0.001_opt_adam.keras\n",
      "312829/312829 - 746s - 2ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1489 - loss: 1.2425e-12 - precision_m: 127.9121 - recall_m: 127.9121 - true_positive_rate_m: 127.9121 - val_accuracy: 1.0000 - val_f1_score_m: 0.9992 - val_false_positive_rate_m: 0.0243 - val_loss: 1.3727e-13 - val_precision_m: 127.9232 - val_recall_m: 127.9232 - val_true_positive_rate_m: 127.9232\n",
      "Epoch 5: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m623853/623853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m650s\u001b[0m 1ms/step\n",
      "CPU times: user 3h 28min 36s, sys: 1h 24min 15s, total: 4h 52min 51s\n",
      "Wall time: 1h 18min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hidden_layers_options = [0]\n",
    "learning_rates = [0.001]\n",
    "optimizers = ['adam']\n",
    "save_dir = \"/home/sagemaker-user/model\"\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "for optimizer_type in optimizers:\n",
    "    for num_hidden_layers in hidden_layers_options:\n",
    "        for lr in learning_rates:\n",
    "            print(f\"\\nTraining model with {num_hidden_layers} hidden layers, learning rate {lr}, optimizer {optimizer_type}\")\n",
    "            model = create_lstm_model(num_hidden_layers=num_hidden_layers, learning_rate=lr, optimizer_type=optimizer_type)\n",
    "\n",
    "            # Define model checkpoint to save models based on FPR score\n",
    "            checkpoint_filepath = f\"{save_dir}/checkpoint_hidden_{num_hidden_layers}_lr_{lr}_opt_{optimizer_type}.keras\"\n",
    "\n",
    "            model_checkpoint = ModelCheckpoint(\n",
    "                checkpoint_filepath,\n",
    "                monitor='false_positive_rate_m',  \n",
    "                mode='min',               # Since you're monitoring F1 score, mode is 'max'\n",
    "                verbose=2                 # Print saving info\n",
    "            )            \n",
    "    \n",
    "            # Early stopping to prevent overfitting\n",
    "            early_stopping = EarlyStopping(monitor='false_positive_rate_m', \n",
    "                                           mode='min', patience=3,  \n",
    "                                           restore_best_weights=True,\n",
    "                                           verbose=2,\n",
    "                                          )\n",
    "            with tf.device(\"/cpu:0\"):\n",
    "                # Train the model\n",
    "                history = model.fit(\n",
    "                    X_train_reshaped, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2,\n",
    "                    class_weight=class_weights,\n",
    "                    callbacks=[early_stopping, model_checkpoint],\n",
    "                    verbose=2 \n",
    "                )\n",
    "    \n",
    "                # After training, load the best saved model\n",
    "                model.load_weights(checkpoint_filepath)\n",
    "                \n",
    "                # Evaluate the model\n",
    "                y_pred_prob = model.predict(X_test_reshaped)\n",
    "                y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "                \n",
    "                # Compute evaluation metrics\n",
    "                report = classification_report(y_test, y_pred, output_dict=True)\n",
    "                roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "                # Compute confusion matrix for FPR and TPR\n",
    "                cm = confusion_matrix(y_test, y_pred)\n",
    "                tn, fp, fn, tp = cm.ravel()\n",
    "                fpr_value = fp / (fp + tn + 1e-7)\n",
    "                tpr_value = tp / (tp + fn + 1e-7)\n",
    "    \n",
    "                # Save the trained model after each iteration\n",
    "                model_filename = f\"{save_dir}/model_hidden_{num_hidden_layers}_lr_{lr}_opt_{optimizer_type}.keras\"\n",
    "                model.save(model_filename)\n",
    "                \n",
    "                # Store the results\n",
    "                results.append({\n",
    "                    'optimizer': optimizer_type,\n",
    "                    'hidden_layers': num_hidden_layers,\n",
    "                    'learning_rate': lr,\n",
    "                    'accuracy': report['accuracy'],\n",
    "                    'precision': report['1']['precision'],\n",
    "                    'recall': report['1']['recall'],\n",
    "                    'f1_score': report['1']['f1-score'],\n",
    "                    'roc_auc': roc_auc,\n",
    "                    'fpr': fpr_value,\n",
    "                    'tpr': tpr_value,\n",
    "                    'history': history.history\n",
    "                }\n",
    "                              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aece764-0ee5-4f99-a3a7-865d16aaf0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model with 0 hidden layers, learning rate 0.001, optimizer adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-01 12:55:27.617808: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 22423518320 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\n",
      "Epoch 4: saving model to /home/sagemaker-user/model/checkpoint_hidden_0_lr_0.001_opt_adam.keras\n",
      "312829/312829 - 731s - 2ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1487 - loss: 1.0080e-12 - precision_m: 127.9120 - recall_m: 127.9120 - true_positive_rate_m: 127.9120 - val_accuracy: 1.0000 - val_f1_score_m: 0.9992 - val_false_positive_rate_m: 0.0243 - val_loss: 1.3345e-13 - val_precision_m: 127.9232 - val_recall_m: 127.9232 - val_true_positive_rate_m: 127.9232\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 5: saving model to /home/sagemaker-user/model/checkpoint_hidden_0_lr_0.001_opt_adam.keras\n",
      "312829/312829 - 736s - 2ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1489 - loss: 8.7637e-13 - precision_m: 127.9119 - recall_m: 127.9119 - true_positive_rate_m: 127.9119 - val_accuracy: 1.0000 - val_f1_score_m: 0.9992 - val_false_positive_rate_m: 0.0243 - val_loss: 1.2873e-13 - val_precision_m: 127.9232 - val_recall_m: 127.9232 - val_true_positive_rate_m: 127.9232\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 6: saving model to /home/sagemaker-user/model/checkpoint_hidden_0_lr_0.001_opt_adam.keras\n",
      "312829/312829 - 732s - 2ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1490 - loss: 7.8491e-13 - precision_m: 127.9128 - recall_m: 127.9128 - true_positive_rate_m: 127.9128 - val_accuracy: 1.0000 - val_f1_score_m: 0.9992 - val_false_positive_rate_m: 0.0243 - val_loss: 1.2294e-13 - val_precision_m: 127.9232 - val_recall_m: 127.9232 - val_true_positive_rate_m: 127.9232\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 7: saving model to /home/sagemaker-user/model/checkpoint_hidden_0_lr_0.001_opt_adam.keras\n",
      "312829/312829 - 736s - 2ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1487 - loss: 7.1562e-13 - precision_m: 127.9123 - recall_m: 127.9123 - true_positive_rate_m: 127.9123 - val_accuracy: 1.0000 - val_f1_score_m: 0.9992 - val_false_positive_rate_m: 0.0243 - val_loss: 1.1569e-13 - val_precision_m: 127.9232 - val_recall_m: 127.9232 - val_true_positive_rate_m: 127.9232\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 8: saving model to /home/sagemaker-user/model/checkpoint_hidden_0_lr_0.001_opt_adam.keras\n",
      "312829/312829 - 731s - 2ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1489 - loss: 6.5708e-13 - precision_m: 127.9130 - recall_m: 127.9130 - true_positive_rate_m: 127.9130 - val_accuracy: 1.0000 - val_f1_score_m: 0.9992 - val_false_positive_rate_m: 0.0243 - val_loss: 1.1213e-13 - val_precision_m: 127.9232 - val_recall_m: 127.9232 - val_true_positive_rate_m: 127.9232\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 9: saving model to /home/sagemaker-user/model/checkpoint_hidden_0_lr_0.001_opt_adam.keras\n",
      "312829/312829 - 736s - 2ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1489 - loss: 6.1091e-13 - precision_m: 127.9124 - recall_m: 127.9124 - true_positive_rate_m: 127.9124 - val_accuracy: 1.0000 - val_f1_score_m: 0.9992 - val_false_positive_rate_m: 0.0243 - val_loss: 1.0879e-13 - val_precision_m: 127.9232 - val_recall_m: 127.9232 - val_true_positive_rate_m: 127.9232\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 10: saving model to /home/sagemaker-user/model/checkpoint_hidden_0_lr_0.001_opt_adam.keras\n",
      "312829/312829 - 731s - 2ms/step - accuracy: 1.0000 - f1_score_m: 0.9983 - false_positive_rate_m: 0.1488 - loss: 5.7433e-13 - precision_m: 127.9122 - recall_m: 127.9122 - true_positive_rate_m: 127.9122 - val_accuracy: 1.0000 - val_f1_score_m: 0.9992 - val_false_positive_rate_m: 0.0243 - val_loss: 1.0449e-13 - val_precision_m: 127.9232 - val_recall_m: 127.9232 - val_true_positive_rate_m: 127.9232\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\u001b[1m483770/623853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2:28\u001b[0m 1ms/step"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hidden_layers_options = [0]\n",
    "learning_rates = [0.001]\n",
    "optimizers = ['adam']\n",
    "save_dir = \"/home/sagemaker-user/model\"\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "for optimizer_type in optimizers:\n",
    "    for num_hidden_layers in hidden_layers_options:\n",
    "        for lr in learning_rates:\n",
    "            print(f\"\\nTraining model with {num_hidden_layers} hidden layers, learning rate {lr}, optimizer {optimizer_type}\")\n",
    "            model = create_lstm_model(num_hidden_layers=num_hidden_layers, learning_rate=lr, optimizer_type=optimizer_type)\n",
    "\n",
    "            # Define model checkpoint to save models based on FPR score\n",
    "            checkpoint_filepath = f\"{save_dir}/checkpoint_hidden_{num_hidden_layers}_lr_{lr}_opt_{optimizer_type}.keras\"\n",
    "\n",
    "            model_checkpoint = ModelCheckpoint(\n",
    "                checkpoint_filepath,\n",
    "                monitor='false_positive_rate_m',  \n",
    "                mode='min',               # Since you're monitoring F1 score, mode is 'max'\n",
    "                verbose=2                 # Print saving info\n",
    "            )            \n",
    "    \n",
    "            # Early stopping to prevent overfitting\n",
    "            early_stopping = EarlyStopping(monitor='false_positive_rate_m', \n",
    "                                           mode='min', patience=3,  \n",
    "                                           restore_best_weights=True,\n",
    "                                           start_from_epoch = 2,\n",
    "                                           verbose=2,\n",
    "                                          )\n",
    "            with tf.device(\"/cpu:0\"):\n",
    "                # Train the model\n",
    "                history = model.fit(\n",
    "                    X_train_reshaped, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2,\n",
    "                    class_weight=class_weights,\n",
    "                    callbacks=[early_stopping, model_checkpoint],\n",
    "                    verbose=2 \n",
    "                )\n",
    "    \n",
    "                # After training, load the best saved model\n",
    "                model.load_weights(checkpoint_filepath)\n",
    "                \n",
    "                # Evaluate the model\n",
    "                y_pred_prob = model.predict(X_test_reshaped)\n",
    "                y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "                \n",
    "                # Compute evaluation metrics\n",
    "                report = classification_report(y_test, y_pred, output_dict=True)\n",
    "                roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "                # Compute confusion matrix for FPR and TPR\n",
    "                cm = confusion_matrix(y_test, y_pred)\n",
    "                tn, fp, fn, tp = cm.ravel()\n",
    "                fpr_value = fp / (fp + tn + 1e-7)\n",
    "                tpr_value = tp / (tp + fn + 1e-7)\n",
    "    \n",
    "                # Save the trained model after each iteration\n",
    "                model_filename = f\"{save_dir}/model_hidden_{num_hidden_layers}_lr_{lr}_opt_{optimizer_type}.keras\"\n",
    "                model.save(model_filename)\n",
    "                \n",
    "                # Store the results\n",
    "                results.append({\n",
    "                    'optimizer': optimizer_type,\n",
    "                    'hidden_layers': num_hidden_layers,\n",
    "                    'learning_rate': lr,\n",
    "                    'accuracy': report['accuracy'],\n",
    "                    'precision': report['1']['precision'],\n",
    "                    'recall': report['1']['recall'],\n",
    "                    'f1_score': report['1']['f1-score'],\n",
    "                    'roc_auc': roc_auc,\n",
    "                    'fpr': fpr_value,\n",
    "                    'tpr': tpr_value,\n",
    "                    'history': history.history\n",
    "                }\n",
    "                              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b163d58-7924-45f1-a6c8-2acbfb0145fe",
   "metadata": {},
   "source": [
    "# Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7194a79c-162d-465a-be50-bc8e00e33015",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in best_models.iterrows():\n",
    "    model = create_lstm_model(num_hidden_layers=row['hidden_layers'],\n",
    "                              learning_rate=row['learning_rate'],\n",
    "                              optimizer_type=row['optimizer'])\n",
    "    # Train the model\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=10,\n",
    "        batch_size=64,\n",
    "        validation_split=0.2,\n",
    "        class_weight=class_weights,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "    disp.plot()\n",
    "    plt.title(f'Confusion Matrix - Optimizer: {row[\"optimizer\"]}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd88af83-3887-413c-b026-0965d37eaa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss (Learning Rate: {}, Hidden Layers: {})'.format(lr, num_hidden_layers))\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dcfb4c-1233-449c-825f-ab6464ac8382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting F1-Score vs Learning Rate for each Optimizer and Hidden Layer combination\n",
    "for optimizer_type in optimizers:\n",
    "    for num_hidden_layers in hidden_layers_options:\n",
    "        subset = results_df[(results_df['optimizer'] == optimizer_type) & \n",
    "                            (results_df['hidden_layers'] == num_hidden_layers)]\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.barplot(x='learning_rate', y='f1_score', data=subset)\n",
    "        plt.title(f'Optimizer: {optimizer_type}, Hidden Layers: {num_hidden_layers}')\n",
    "        plt.xlabel('Learning Rate')\n",
    "        plt.ylabel('F1-Score')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dfc2c3-6081-4ec6-bb06-7f7cdda4981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='optimizer', y='f1_score', data=best_models)\n",
    "plt.title('Best F1-Score for Each Optimizer')\n",
    "plt.xlabel('Optimizer')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6cbcaf-7321-4fe0-9ba9-d6202dada834",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in best_models.iterrows():\n",
    "    history = row['history']\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(history['loss'], label='Training Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f\"Loss Curve - Optimizer: {row['optimizer']}, Hidden Layers: {row['hidden_layers']}, LR: {row['learning_rate']}\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efad208-3edb-468a-9344-a00af670a451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Plot ROC-AUC for each optimizer\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='optimizer', y='roc_auc', data=best_models)\n",
    "plt.title('Best ROC-AUC for Each Optimizer')\n",
    "plt.xlabel('Optimizer')\n",
    "plt.ylabel('ROC-AUC')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
